# 常见问题

## 基础模型
#### 1.对于图编译路线厂商，模型性能测试时是否可以去除first step图编译耗时​。

可以，同样也适用于图编译的推理引擎​。

#### 2. 在评分时是否可以考虑不同的整卡功耗或理论算力。在理论算力存在较大差异时，计算模型或算子分数时是否可以做一些折算？

基础规格的评分分段充分考虑了各家厂商的分布情况，主要体现分档，而非得分，会根据厂商发展不定期调整​。

#### 3. 测试使用数据集是否可以变更，还是必须要使用官网提供的数据集？

数据集不能变更。
    
#### 4. 是否可以提供涉及测试指标的英伟达基准值？

基准值见数据收集表（数据收集表可见评测实施方案链接）

#### 5. 除了可定量比较的模型性能指标如吞吐量，其他一些能效比、软件生态、稳定性、成本等，报告中是否会对所有指标进行GPU的横向比较​？

目前针对国产芯片的评测基础规格的评测目前还比较主观，因此该项的权重也较低，但以后的发展方向用量化客观的手段来评测。同样成本的考察受销售渠道等因素的影响，实验室做出来的训练或推理成本也不准确。

---

## 大模型

#### 1. 大模型训练测试中，GPT-3-175B目前尚未适配，是否可使用GPT-3-110B进行替代测试？

如果没有适配可以暂时略过。

#### 2. stable diffusion目前仅适配推理模型，其训练模型是否必须要进行测试？

sd预训练需要测试，如果没有适配可以暂时略过。

#### 3. 微调评测中的Alpaca-lora模型是否就是llama-7b的lora微调？

是的，所有模型测试可以参考代码库[readme](https://github.com/DeepLink-org/AIChipBenchmark/blob/main/models/readme.md)。

#### 4. 训练internlm的任务本次是否可以先用llama训练代替​？

internlm可以用llama等效参数替代​。

---
## 无法找到问题
* 您可在项目中提交issue，将您遇到的问题告诉我们；
* 可通过官方渠道与我们联系，并向我们反馈您所遇到的问题，联系邮箱：deeplink_benchmark@pjlab.org.cn。
<!-- issue回复的流程可在[开发者指南中](Contributors.md)获取。
2. 或者您也可以加入[开发者社区]()，像我们提供反馈和建议。 -->
